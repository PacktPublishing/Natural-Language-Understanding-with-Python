{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd145e0c-607c-4313-972a-5289f9cd0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using nltk\n",
    "import nltk\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "text = \"we'd like to book a flight from boston to london\"\n",
    "tokenized_text = word_tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a139eeb0-e574-488b-8649-e4cf0718dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "FreqDist(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bb5f30-d63d-4576-8a41-6177cf0c9b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.pos_tag(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a08b73-8c41-43e3-9a90-ab5ef4d79386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text with SpaCy\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "text = \"we'd like to book a flight from boston to london\"\n",
    "\n",
    "doc = nlp(text)\n",
    "print ([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1632d91-da71-4a8e-a3c0-4dda54047718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an array of tokens\n",
    "words = [token.text for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b963cb0-afe5-4320-86e3-6a2f2d73f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect word frequency statistics with SpaCy\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_freq = Counter(words)\n",
    "print(word_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de3b3e-461f-4603-80bd-8f95d1731f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just as with NLTK, we can perform POS tagging with spaCy:\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b4fb4-fc27-4f20-99e6-e8e2da8e9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a8279-b005-455a-8e2d-adbe9e6e7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"we'd like to book a flight from boston to new york\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc,style='ent',jupyter=True,options={'distance':200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eef45d-2da9-45a5-9f74-605c18d5de80",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('they get in an accident')\n",
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b72ea0-8a86-487d-be2c-c68bb31e2495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP imports\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# general numerical and visualization imports\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28778dd-b756-42b6-a37c-34fb7e5a10f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the nltk downloader\n",
    "# note that the downloader might be minimized in your toolbar\n",
    "# the downloader is a modal window, so the Jupyter notebook will wait for you to do something with it\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b4c5b-301e-434b-8604-769891970cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the training data\n",
    "from nltk.corpus import movie_reviews\n",
    "sents = movie_reviews.sents()\n",
    "print(sents)\n",
    "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church',\n",
    "'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get',\n",
    "'into', 'an', 'accident', '.'], ...]\n",
    "\n",
    "sample = sents[9]\n",
    "print(sample)\n",
    "['they', 'seem', 'to', 'have', 'taken', 'this', 'pretty', 'neat',\n",
    "'concept', ',', 'but', 'executed', 'it', 'terribly', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899de856-86fe-4f07-bbba-ad0315f8400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the most frequent 25 words\n",
    "words = movie_reviews.words()\n",
    "word_counts = nltk.FreqDist(word.lower() for word in words if word.\n",
    "isalpha())\n",
    "top_words = word_counts.most_common(25)\n",
    "all_fdist = pd.Series(dict(top_words))\n",
    "# Setting fig and ax into variables\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "# Plot with Seaborn plotting tools\n",
    "plt.xticks(rotation = 70)\n",
    "plt.title(\"Frequency -- Top 25 Words in the Movie Review Corpus\",\n",
    "fontsize = 30)\n",
    "plt.xlabel(\"Words\", fontsize = 30)\n",
    "plt.ylabel(\"Frequency\", fontsize = 30)\n",
    "all_plot = sns.barplot(x = all_fdist.index, y = all_fdist.values,\n",
    "ax=ax)\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87497209-e2dd-447a-b26a-81253c985e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying a WordCloud\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(background_color = 'white',\n",
    "\n",
    "max_words = 25,\n",
    "relative_scaling = 0,\n",
    "width = 600,height = 300,\n",
    "max_font_size = 150,\n",
    "colormap = 'Dark2',\n",
    "min_font_size = 10).generate_from_frequencies(all_fdist)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce0527c-ab15-4019-b861-fe9e8293b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at part of speech frequency in the movie corpus\n",
    "movie_reviews_sentences = movie_reviews.sents()\n",
    "tagged_sentences = nltk.pos_tag_sents(movie_reviews_sentences)\n",
    "total_counts = {}\n",
    "for sentence in tagged_sentences:\n",
    "    counts = Counter(tag for word,tag in sentence)\n",
    "    total_counts = Counter(total_counts) + Counter(counts)\n",
    "sorted_tag_list = sorted(total_counts.items(), key = lambda x:\n",
    "x[1],reverse = True)\n",
    "all_tags = pd.DataFrame(sorted_tag_list)\n",
    "most_common_tags = all_tags.head(18)\n",
    "\n",
    "# Setting figure and ax into variables\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "all_plot = sns.barplot(x = most_common_tags[0], y = most_common_tags[1], ax = ax)\n",
    "plt.xticks(rotation = 70)\n",
    "plt.title(\"Part of Speech Frequency in Movie Review Corpus\", fontsize\n",
    "= 30)\n",
    "plt.xlabel(\"Part of Speech\", fontsize = 30)\n",
    "plt.ylabel(\"Frequency\", fontsize = 30)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
