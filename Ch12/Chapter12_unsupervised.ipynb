{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf8805-0466-4103-bc64-d94d98681db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bertopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# Prepare embeddings\n",
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "#The model is a Hugging Face transformer model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "corpus_embeddings = embedding_model.encode(docs, show_progress_bar = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bca490-18be-491d-bd3d-429daa14ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look at the actual embeddings\n",
    "corpus_embeddings.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d008e2-17d4-43e8-8eae-eeec25e4b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords should not be removed from the documents before preparing the embeddings because the\n",
    "# transformers have been trained on normal text, including stopwords. However, it can be useful to\n",
    "# remove stopwords later. This can be done by including a CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_model = CountVectorizer(stop_words = \"english\", max_df = .95, min_df = .01)\n",
    "# vectorizer_model = CountVectorizer(stop_words = \"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335182f7-6d17-49c7-8145-153039c8b332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters for HDBSCAN (clustering) and UMAP (dimensionality reduction)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size = 30, metric = 'euclidean', prediction_data = True)\n",
    "umap_model = UMAP(n_neighbors = 15, n_components = 10, metric = 'cosine', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae82ea-61a3-4fff-8331-32cba8e8f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BERTopic\n",
    "model = BERTopic(\n",
    "    n_gram_range=(1, 3),\n",
    "    vectorizer_model = vectorizer_model,\n",
    "    nr_topics = 40,\n",
    "    top_n_words = 10,\n",
    "    umap_model = umap_model,\n",
    "    hdbscan_model = hdbscan_model,\n",
    "    min_topic_size = 30,\n",
    "    calculate_probabilities = True).fit(docs, corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e344fcd-f4d6-4548-9cea-e586559692e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get interesting properties of the model\n",
    "topics, probabilities = model.transform(docs, corpus_embeddings)\n",
    "df_topic_freq = model.get_topic_freq()\n",
    "print(df_topic_freq)\n",
    "topics_count = len(df_topic_freq) - 1\n",
    "corpus_embeddings.view()\n",
    "model.visualize_barchart(top_n_topics=topics_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e1dfc-1660-48c4-a9fe-727070a5de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfe1ee-5ad2-4e7f-bddb-719a011a1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some visualizations\n",
    "fig = model.visualize_documents(docs, embeddings = corpus_embeddings, sample = .6, topics = [0,1,2,3,4,5,6],\n",
    "                          hide_annotations = False, hide_document_hover = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d775b-418a-4311-97e9-aa8f40e69de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"./clusters.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a3ee8-add7-49b9-906d-ac4c3c1df10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = model.visualize_barchart()\n",
    "fig2.write_image(\"./barchart.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8798a4-4e80-4db8-bc14-564a8d3ab64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "new_docs = [\"I'm looking for a new graphics card\",\"when is the next nasa launch\"]\n",
    "embeddings = sentence_model.encode(new_docs)\n",
    "topics, probs = model.transform(new_docs,embeddings)\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171269fe-7aa6-47e7-a6b9-de6e6d85e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topics,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c67fd-a4f9-49f5-b141-86aee1a03c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = model.get_topics()\n",
    "topic_info = model.get_topic_info()\n",
    "topic_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
