{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d4be8-1345-46c8-8738-e84f9ff1555c",
   "metadata": {
    "id": "6IwI_2bcIeX8"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 100\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/train',\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset ='validation',\n",
    "    seed = seed)\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    'aclImdb/test',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10d65d-f81b-44d0-a703-0e42723d14f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels_train = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "movies_train = np.concatenate([x for x, y in train_ds], axis = 0)\n",
    "\n",
    "labels_val = np.concatenate([y for x, y in val_ds], axis=0)\n",
    "movies_val = np.concatenate([x for x, y in val_ds], axis = 0)\n",
    "\n",
    "labels_test = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "movies_test = np.concatenate([x for x, y in test_ds], axis = 0)\n",
    "\n",
    "validation_data = movies_val,labels_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-beauty",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize TfidfVectorizer to create the tfIdf representation of the corpus\n",
    "# the parameters are: min_df is the percentage of documents that the word has to \n",
    "# occur in to be considered, the tokenizer to use, and the maximum\n",
    "# number of words to consider\n",
    "vectorizer = TfidfVectorizer(min_df=.1, \n",
    "                             tokenizer=nltk.word_tokenize, \n",
    "                             max_features= 1000) \n",
    "\n",
    "# fit and transform using training text \n",
    "# here is where we build the tfidf representation of the training data\n",
    "movies_train_tfidf = vectorizer.fit_transform(movies_train)\n",
    "#movies_train_tfidf = vectorizer.transform(movies_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to predict the classes of the test data\n",
    "# We will use Multinominal Naive Bayes as our classifier\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifier and train it\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(movies_train_tfidf, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy based on test set\n",
    "movies_test_tfidf = vectorizer.transform(movies_test)\n",
    "labels_pred = classifier.predict(movies_test_tfidf)\n",
    "sklearn.metrics.accuracy_score(labels_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-screening",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# View the results as a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(labels_test, labels_pred,normalize=None)\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the confusion matrix\n",
    "# uncomment the next line if you want the plots to appear inline\n",
    "# matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,f1_score,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = conf_matrix,\n",
    "                               display_labels = class_names)\n",
    "print(class_names)\n",
    "disp.plot(xticks_rotation=75,cmap=plt.cm.Blues)\n",
    "plt.savefig('confusionTfidf.svg')\n",
    "plt.show()\n",
    "print(classification_report(labels_test, labels_pred, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
