{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba57a260-028b-463c-96f6-7a6d70ac8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing emojis with their intepretation\n",
    "import demoji\n",
    "\n",
    "happy_birthday = \"Happy birthday!üéÇ\"\n",
    "\n",
    "text_with_emojis_replaced = demoji.replace_with_desc(happy_birthday)\n",
    "print(text_with_emojis_replaced)\n",
    "\n",
    "text_with_emojis_removed = demoji.replace(happy_birthday,\"\")\n",
    "print(text_with_emojis_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725ab24-1875-4f4d-b835-8c9eb6dc8b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove smart quotes\n",
    "text = \"here is a string with ‚Äúsmart‚Äù quotes\"\n",
    "text = text.replace(\"‚Äú\", \"\\\"\").replace(\"‚Äù\",\"\\\"\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a283761-3136-4bd5-8dcd-02ec17e0db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two examples of tokenization\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# a set of a few sentences to illustrate tokenization\n",
    "#text = [\"Walk here.\", \"Walk  here.\", \"Don't walk here.\", \"$100\"]\n",
    "text = [\"Walk--don't run\"]\n",
    "\n",
    "print(\"Split on white space\")\n",
    "\n",
    "for sentence in text:\n",
    "    tokenized = sentence.split(\" \")\n",
    "    print(tokenized)\n",
    "\n",
    "print(\"Using NLTK tokenization\")\n",
    "\n",
    "for sentence in text:\n",
    "    tokenized = word_tokenize(sentence)\n",
    "    print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f5ad76-d611-4992-8857-ccf631bfdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercasing\n",
    "\n",
    "mixed_text = \"WALK! Going for a walk is great exercise.\"\n",
    "mixed_words = nltk.word_tokenize(mixed_text)\n",
    "print(mixed_words)\n",
    "\n",
    "lower_words = []\n",
    "for mixed_word in mixed_words:\n",
    "    lower_words.append(mixed_word.lower())\n",
    "print(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545716e-b0e0-4d0f-962c-4ad603f37d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming with the Porter Stemmer\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "text_to_stem = \"Going for a walk is the best exercise. I've walked every evenin this week.\"\n",
    "tokenized_to_stem = nltk.word_tokenize(text_to_stem)\n",
    "stemmed = [stemmer.stem(w) for w in tokenized_to_stem]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aad1b5-efe2-4b56-860b-b0f2b4a503cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizing with WordNet\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict\n",
    "\n",
    "# align names for parts of speech between WordNet and part of speech tagger.\n",
    "tag_map = defaultdict(lambda: wordnet.NOUN)\n",
    "tag_map[\"J\"] = wordnet.ADJ\n",
    "tag_map[\"V\"] = wordnet.VERB\n",
    "tag_map[\"R\"] = wordnet.ADJ\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_to_lemmatize = (\n",
    "    \"going for a walk is the best exercise. i've walked every evening this week\"\n",
    ")\n",
    "print(\"text to lemmatize is: \\n\", text_to_lemmatize)\n",
    "\n",
    "tokens_to_lemmatize = nltk.word_tokenize(text_to_lemmatize)\n",
    "lemmatized_result = \"\"\n",
    "for token, tag in pos_tag(tokens_to_lemmatize):\n",
    "    lemma = lemmatizer.lemmatize(token, tag_map[tag[0]])\n",
    "    lemmatized_result = lemmatized_result + \" \" + lemma\n",
    "print(\"lemmatized result is: \\n\", lemmatized_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88e174-8307-4861-9d44-3967036de485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(nltk_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97159e-69ad-4214-92af-97bc8029db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = nlp.Defaults.stop_words\n",
    "print(spacy_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6935d0-a143-4fed-b391-d3939b2c7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation\n",
    "# define a sample text and tokenize it\n",
    "text_to_remove_punct = \"going for a walk is the best exercise!! I've walked, I believe, every evening this week.\"\n",
    "tokens_to_remove_punct = nltk.word_tokenize(text_to_remove_punct)\n",
    "\n",
    " # remove punctuation\n",
    "tokens_no_punct = [word for word in tokens_to_remove_punct if word.isalnum()]\n",
    "print(tokens_no_punct)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4ee16-cb2d-4912-b591-293bc3607857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell_checker = SpellChecker()\n",
    "\n",
    "# find words that may represent spelling errors\n",
    "text_to_spell_check = \"Ms. Ramalingam voted agains the bill\"  \n",
    "tokens_to_spell_check = nltk.word_tokenize(text_to_spell_check)\n",
    "spelling_errors = spell_checker.unknown(tokens_to_spell_check)\n",
    "\n",
    "for misspelled in spelling_errors:\n",
    "    # Get the one `most likely` answer\n",
    "    print(misspelled, \" should be\", spell_checker.correction(misspelled))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
